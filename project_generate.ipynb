{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(data_file,train_test = 'train'):\n",
    "    if train_test == 'train':\n",
    "        with open(data_file, 'r', encoding = 'utf-8') as fd:\n",
    "            data = [l.strip().split('\\t') for l in fd.readlines()][1:]\n",
    "        X = [d[2] for d in data]\n",
    "        y = [d[1] for d in data]\n",
    "        return X, y\n",
    "    elif train_test == \"test\":\n",
    "        with open(data_file, 'r') as fd:\n",
    "            data = [l.strip().split('\\t') for l in fd.readlines()][1:]\n",
    "        X = [d[1] for d in data]\n",
    "        return X        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweet, train_label = parse_csv('data/train/SemEval2018-T3-train-taskA_emoji_ironyHashtags.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet, test_label = parse_csv('data/gold/SemEval2018-T3_gold_test_taskA_emoji.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_loc = list(map(int, train_label))\n",
    "test_label_loc =  list(map(int, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = itemgetter(*[i for i, e in enumerate(train_label_loc) if e])(train_tweet) + itemgetter(*[i for i, e in enumerate(test_label_loc) if e])(test_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"train\": (train_tweet, train_label),\n",
    "    \"gold\": (test_tweet, test_label),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_preprocess():\n",
    "    preprocessor = TextPreProcessor(\n",
    "        normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "                   'time',\n",
    "                   'date', 'number'],\n",
    "        annotate={\"hashtag\", \"elongated\", \"allcaps\", \"repeated\", 'emphasis',\n",
    "                  'censored'},\n",
    "        all_caps_tag=\"wrap\",\n",
    "        fix_text=True,\n",
    "        segmenter=\"twitter_2018\",\n",
    "        corrector=\"twitter_2018\",\n",
    "        unpack_hashtags=True,\n",
    "        unpack_contractions=True,\n",
    "        spell_correct_elong=False,\n",
    "        tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "        dicts=[emoticons]\n",
    "    ).pre_process_doc\n",
    "\n",
    "    def preprocess(name, dataset):\n",
    "        desc = \"PreProcessing dataset {}...\".format(name)\n",
    "\n",
    "        data = [preprocessor(x)\n",
    "                for x in tqdm(dataset, desc=desc)]\n",
    "        return data\n",
    "\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter_2018 - 1grams ...\n",
      "Reading twitter_2018 - 2grams ...\n",
      "Reading twitter_2018 - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "pre = twitter_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset None...: 100%|█████████████████████████████████████████████| 3834/3834 [00:02<00:00, 1819.34it/s]\n"
     ]
    }
   ],
   "source": [
    "a = pre(None,train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./embeddings\\\\ntua_twitter_affect_310.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conf = {\n",
    "    \"name\": \"TASK3_B\",\n",
    "    \"token_type\": \"word\",\n",
    "    \"batch_train\": 32,\n",
    "    \"batch_eval\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"embeddings_file\": \"ntua_twitter_affect_310\",\n",
    "    \"embed_dim\": 310,\n",
    "    \"embed_finetune\": False,\n",
    "    \"embed_noise\": 0.2,\n",
    "    \"embed_dropout\": 0.1,\n",
    "    \"encoder_dropout\": 0.2,\n",
    "    \"encoder_size\": 150,\n",
    "    \"encoder_layers\": 2,\n",
    "    \"encoder_bidirectional\": True,\n",
    "    \"attention\": True,\n",
    "    \"attention_layers\": 1,\n",
    "    \"attention_context\": False,\n",
    "    \"attention_activation\": \"tanh\",\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"base\": 0.3,\n",
    "    \"patience\": 10,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"clip_norm\": 1,\n",
    "}\n",
    "os.path.join(BASE_PATH, \"embeddings\",\n",
    "                                \"{}.txt\".format(model_conf[\"embeddings_file\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import pickle\n",
    "\n",
    "def file_cache_name(file):\n",
    "    head, tail = os.path.split(file)\n",
    "    filename, ext = os.path.splitext(tail)\n",
    "    return os.path.join(head, filename + \".p\")\n",
    "\n",
    "\n",
    "def write_cache_word_vectors(file, data):\n",
    "    with open(file_cache_name(file), 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file)\n",
    "\n",
    "\n",
    "def load_cache_word_vectors(file):\n",
    "    with open(file_cache_name(file), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def load_word_vectors(file, dim):\n",
    "    \"\"\"\n",
    "    Read the word vectors from a text file\n",
    "    Args:\n",
    "        file (): the filename\n",
    "        dim (): the dimensions of the word vectors\n",
    "\n",
    "    Returns:\n",
    "        word2idx (dict): dictionary of words to ids\n",
    "        idx2word (dict): dictionary of ids to words\n",
    "        embeddings (np.ndarray): the word embeddings matrix\n",
    "\n",
    "    \"\"\"\n",
    "    # in order to avoid this time consuming operation, cache the results\n",
    "    try:\n",
    "        cache = load_cache_word_vectors(file)\n",
    "        print(\"Loaded word embeddings from cache.\")\n",
    "        return cache\n",
    "    except OSError:\n",
    "        print(\"Didn't find embeddings cache file {}\".format(file))\n",
    "\n",
    "    # create the necessary dictionaries and the word embeddings matrix\n",
    "    if os.path.exists(file):\n",
    "        print('Indexing file {} ...'.format(file))\n",
    "\n",
    "        word2idx = {}  # dictionary of words to ids\n",
    "        idx2word = {}  # dictionary of ids to words\n",
    "        embeddings = []  # the word embeddings matrix\n",
    "\n",
    "        # create the 2D array, which will be used for initializing\n",
    "        # the Embedding layer of a NN.\n",
    "        # We reserve the first row (idx=0), as the word embedding,\n",
    "        # which will be used for zero padding (word with id = 0).\n",
    "        embeddings.append(np.zeros(dim))\n",
    "\n",
    "        # flag indicating whether the first row of the embeddings file\n",
    "        # has a header\n",
    "        header = False\n",
    "\n",
    "        # read file, line by line\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for i, line in enumerate(f, 1):\n",
    "\n",
    "                # skip the first row if it is a header\n",
    "                if i == 1:\n",
    "                    if len(line.split()) < dim:\n",
    "                        header = True\n",
    "                        continue\n",
    "\n",
    "                values = line.split(\" \")\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "                index = i - 1 if header else i\n",
    "\n",
    "                idx2word[index] = word\n",
    "                word2idx[word] = index\n",
    "                embeddings.append(vector)\n",
    "\n",
    "            # add an unk token, for OOV words\n",
    "            if \"<unk>\" not in word2idx:\n",
    "                idx2word[len(idx2word) + 1] = \"<unk>\"\n",
    "                word2idx[\"<unk>\"] = len(word2idx) + 1\n",
    "                embeddings.append(\n",
    "                    np.random.uniform(low=-0.05, high=0.05, size=dim))\n",
    "\n",
    "            print(set([len(x) for x in embeddings]))\n",
    "\n",
    "            print('Found %s word vectors.' % len(embeddings))\n",
    "            embeddings = np.array(embeddings, dtype='float32')\n",
    "\n",
    "        # write the data to a cache file\n",
    "        write_cache_word_vectors(file, (word2idx, idx2word, embeddings))\n",
    "\n",
    "        return word2idx, idx2word, embeddings\n",
    "\n",
    "    else:\n",
    "        print(\"{} not found!\".format(file))\n",
    "        raise OSError(errno.ENOENT, os.strerror(errno.ENOENT), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(model_conf):\n",
    "    word_vectors = os.path.join(BASE_PATH, \"embeddings\",\n",
    "                                \"{}.txt\".format(model_conf[\"embeddings_file\"]))\n",
    "    word_vectors_size = model_conf[\"embed_dim\"]\n",
    "\n",
    "    # load word embeddings\n",
    "    print(\"loading word embeddings...\")\n",
    "    return load_word_vectors(word_vectors, word_vectors_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n",
      "Loaded word embeddings from cache.\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word, embeddings = load_embeddings(model_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "\n",
    "def vectorize(sequence, el2idx, max_length):\n",
    "    \"\"\"\n",
    "    Covert array of tokens, to array of ids, with a fixed length\n",
    "    and zero padding at the end\n",
    "    Args:\n",
    "        sequence (): a list of elements\n",
    "        el2idx (): dictionary of word to ids\n",
    "        max_length ():\n",
    "        unk_policy (): how to handle OOV words\n",
    "        spell_corrector (): if unk_policy = 'correct' then pass a callable\n",
    "            which will try to apply spell correction to the OOV token\n",
    "\n",
    "\n",
    "    Returns: list of ids with zero padding at the end\n",
    "\n",
    "    \"\"\"\n",
    "    words = np.zeros(max_length).astype(int)\n",
    "\n",
    "    # trim tokens after max length\n",
    "    sequence = sequence[:max_length]\n",
    "\n",
    "    for i, token in enumerate(sequence):\n",
    "        if token in el2idx:\n",
    "            words[i] = el2idx[token]\n",
    "        else:\n",
    "            words[i] = el2idx[\"<unk>\"]\n",
    "\n",
    "    return words\n",
    "\n",
    "class WordDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, word2idx, pre):\n",
    "        \"\"\"\n",
    "        A PyTorch Dataset\n",
    "        What we have to do is to implement the 2 abstract methods:\n",
    "\n",
    "            - __len__(self): in order to let the DataLoader know the size\n",
    "                of our dataset and to perform batching, shuffling and so on...\n",
    "            - __getitem__(self, index): we have to return the properly\n",
    "                processed data-item from our dataset with a given index\n",
    "\n",
    "        Args:\n",
    "            X (): list of training samples\n",
    "            y (): list of training labels\n",
    "            max_length (int): the max length for each sentence.\n",
    "                if 0 then use the maximum length in the dataset\n",
    "            word2idx (dict): a dictionary which maps words to indexes\n",
    "            label_transformer (LabelTransformer):\n",
    "        \"\"\"\n",
    "        self.word2idx = word2idx\n",
    "        \n",
    "        self.data = X\n",
    "        \n",
    "        self.data = pre(None, self.data)\n",
    "        \n",
    "        self.set_max_length()\n",
    "\n",
    "        self.dataset_statistics()\n",
    "\n",
    "    def set_max_length(self):\n",
    "        self.max_length = max([len(x) for x in self.data])\n",
    "\n",
    "    def dataset_statistics(self):\n",
    "        words = Counter()\n",
    "        for x in self.data:\n",
    "            words.update(x)\n",
    "        unks = {w: v for w, v in words.items() if w not in self.word2idx}\n",
    "        # unks = sorted(unks.items(), key=lambda x: x[1], reverse=True)\n",
    "        total_words = sum(words.values())\n",
    "        total_unks = sum(unks.values())\n",
    "\n",
    "        print(\"Total words: {}, Total unks:{} ({:.2f}%)\".format(\n",
    "            total_words, total_unks, total_unks * 100 / total_words))\n",
    "\n",
    "        print(\"Unique words: {}, Unique unks:{} ({:.2f}%)\".format(\n",
    "            len(words), len(unks), len(unks) * 100 / len(words)))\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns the _transformed_ item from the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int):\n",
    "\n",
    "        Returns:\n",
    "            (tuple):\n",
    "                * example (ndarray): vector representation of a training sample\n",
    "                * label (string): the class label\n",
    "                * length (int): the length (tokens) of the sentence\n",
    "                * index (int): the index of the dataitem in the dataset.\n",
    "                  It is useful for getting the raw input for visualizations.\n",
    "        \"\"\"\n",
    "        sample = self.data[index]\n",
    "\n",
    "        # transform the sample and the label,\n",
    "        # in order to feed them to the model\n",
    "        sample = vectorize(sample, self.word2idx, self.max_length)\n",
    "\n",
    "\n",
    "        return sample, len(self.data[index]), index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building word-level datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset None...: 100%|█████████████████████████████████████████████| 2222/2222 [00:00<00:00, 3315.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 48166, Total unks:89 (0.18%)\n",
      "Unique words: 6230, Unique unks:89 (1.43%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "print(\"Building word-level datasets...\")\n",
    "dataset = WordDataset(data, word2idx, pre)\n",
    "batch_size = model_conf[\"batch_train\"]\n",
    "loaders = DataLoader(dataset, batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHelper:\n",
    "    @staticmethod\n",
    "    def _sort_by(lengths):\n",
    "        \"\"\"\n",
    "        Sort batch data and labels by length.\n",
    "        Useful for variable length inputs, for utilizing PackedSequences\n",
    "        Args:\n",
    "            lengths (nn.Tensor): tensor containing the lengths for the data\n",
    "\n",
    "        Returns:\n",
    "            - sorted lengths Tensor\n",
    "            - sort (callable) which will sort a given iterable\n",
    "                according to lengths\n",
    "            - unsort (callable) which will revert a given iterable to its\n",
    "                original order\n",
    "\n",
    "        \"\"\"\n",
    "        batch_size = lengths.size(0)\n",
    "\n",
    "        sorted_lengths, sorted_idx = lengths.sort()\n",
    "        _, original_idx = sorted_idx.sort(0, descending=True)\n",
    "        reverse_idx = torch.linspace(batch_size - 1, 0, batch_size).long()\n",
    "\n",
    "        reverse_idx = reverse_idx.to(device)\n",
    "\n",
    "        sorted_lengths = sorted_lengths[reverse_idx]\n",
    "\n",
    "        def sort(iterable):\n",
    "            if len(iterable.shape) > 1:\n",
    "                return iterable[sorted_idx.data][reverse_idx]\n",
    "            else:\n",
    "                return iterable\n",
    "\n",
    "        def unsort(iterable):\n",
    "            if len(iterable.shape) > 1:\n",
    "                return iterable[reverse_idx][original_idx][reverse_idx]\n",
    "            else:\n",
    "                return iterable\n",
    "\n",
    "        return sorted_lengths, sort, unsort\n",
    "    \n",
    "class RNN(nn.Module, ModelHelper):\n",
    "    def __init__(self, input_size, rnn_size, num_layers,\n",
    "                 bidirectional, dropout, embd):\n",
    "        \"\"\"\n",
    "        A simple RNN Encoder.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): the size of the input features\n",
    "            rnn_size (int):\n",
    "            num_layers (int):\n",
    "            bidirectional (bool):\n",
    "            dropout (float):\n",
    "\n",
    "        Returns: outputs, last_outputs\n",
    "        - **outputs** of shape `(batch, seq_len, hidden_size)`:\n",
    "          tensor containing the output features `(h_t)`\n",
    "          from the last layer of the LSTM, for each t.\n",
    "        - **last_outputs** of shape `(batch, hidden_size)`:\n",
    "          tensor containing the last output features\n",
    "          from the last layer of the LSTM, for each t=seq_len.\n",
    "\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        self.n_layers = num_layers\n",
    "        self.n_hidden = rnn_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=embd.shape[0],embedding_dim=embd.shape[1])\n",
    "        \n",
    "        self.init_embeddings(embd)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=input_size,\n",
    "                           hidden_size=rnn_size,\n",
    "                           num_layers=num_layers,\n",
    "                           bidirectional=bidirectional,\n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "\n",
    "        # the dropout \"layer\" for the output of the RNN\n",
    "        self.drop_rnn = nn.Dropout(dropout)\n",
    "\n",
    "        # define output feature size\n",
    "        self.feature_size = rnn_size\n",
    "\n",
    "        self.linear = nn.Linear(self.feature_size, input_size)\n",
    "            \n",
    "    def init_embeddings(self, weights):\n",
    "        self.embedding.weight = nn.Parameter(torch.from_numpy(weights),requires_grad=False)\n",
    "\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        \"\"\"\n",
    "        This is the heart of the model. This function, defines how the data\n",
    "        passes through the network.\n",
    "        Args:\n",
    "            embs (): word embeddings\n",
    "            lengths (): the lengths of each sentence\n",
    "\n",
    "        Returns: the logits for each class\n",
    "\n",
    "        \"\"\"\n",
    "        # lengths, sort, unsort = self._sort_by(lengths)\n",
    "        # x = sort(x)\n",
    "        \n",
    "        embd = self.embedding(x.long())\n",
    "        \n",
    "        if embd.shape[1] != 1:\n",
    "            embd_input = embd[:,:-1,:]\n",
    "            embd_target = embd[:,1:,:]\n",
    "        else:\n",
    "            embd_input = embd\n",
    "            embd_target = embd\n",
    "        \n",
    "        # pack the batch\n",
    "        # packed = pack_padded_sequence(embd, list(lengths.data),\n",
    "        #                       batch_first=True)\n",
    "        outputs, h = self.rnn(embd_input, h)\n",
    "\n",
    "        # unpack output - no need if we are going to use only the last outputs\n",
    "        # outputs, _ = pad_packed_sequence(out_puts, batch_first=True)\n",
    "\n",
    "        # get the outputs from the last *non-masked* timestep for each sentence\n",
    "        #last_outputs = self.last_timestep(outputs, lengths,\n",
    "        #                                  self.rnn.bidirectional)\n",
    "\n",
    "        # apply dropout to the outputs of the RNN\n",
    "        outputs = self.drop_rnn(outputs)\n",
    "\n",
    "\n",
    "        logits = self.linear(outputs)\n",
    "\n",
    "        return logits, h, embd_target\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        \n",
    "        if (gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model, loaders, epochs=10, lr=0.001, clip=5, print_every=50):\n",
    "    model.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_f = nn.CosineSimilarity(dim=2, eps=1e-08)\n",
    "    \n",
    "    gpu = torch.cuda.is_available()\n",
    "    \n",
    "    if gpu:\n",
    "        device = torch.device('cuda')\n",
    "        model.to(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        counter = 0\n",
    "        h = model.init_hidden(model_conf['batch_train'])\n",
    "        \n",
    "        for i_batch, (X, lengths, index) in enumerate(loaders):\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            gpu = torch.cuda.is_available()\n",
    "            \n",
    "            \n",
    "            if gpu:\n",
    "                X, lengths = X.to(device), lengths.to(device)\n",
    "                \n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            \n",
    "            linear_outputs, h, embd_target = model(X, h)\n",
    "            # print(linear_outputs.shape, embd_target.shape)\n",
    "            loss = loss_f(linear_outputs, embd_target)\n",
    "            loss = (1 - loss)/2\n",
    "            \n",
    "            loss.sum().backward()\n",
    "            \n",
    "            \n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "        \n",
    "            if counter % print_every == 0:\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.sum()))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(model_conf['embed_dim'], model_conf['encoder_size'], model_conf['encoder_layers'], False, model_conf['encoder_dropout'], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(804871, 310)\n",
       "  (rnn): LSTM(310, 150, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (drop_rnn): Dropout(p=0.2)\n",
       "  (linear): Linear(in_features=150, out_features=310, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "    \n",
    "if(gpu):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Step: 50... Loss: 565.2349...\n",
      "Epoch: 2/10... Step: 50... Loss: 532.6721...\n",
      "Epoch: 3/10... Step: 50... Loss: 529.7601...\n",
      "Epoch: 4/10... Step: 50... Loss: 553.4858...\n",
      "Epoch: 5/10... Step: 50... Loss: 512.8134...\n",
      "Epoch: 6/10... Step: 50... Loss: 524.2103...\n",
      "Epoch: 7/10... Step: 50... Loss: 557.9632...\n",
      "Epoch: 8/10... Step: 50... Loss: 536.8785...\n",
      "Epoch: 9/10... Step: 50... Loss: 522.8715...\n",
      "Epoch: 10/10... Step: 50... Loss: 539.6664...\n"
     ]
    }
   ],
   "source": [
    "model_training(model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f_1 = nn.CosineSimilarity(dim=0, eps=1e-08)\n",
    "def predict(model, word, h=None, f = loss_f):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        np.random.seed(4)\n",
    "        # tensor inputs\n",
    "        x = word2idx[word]\n",
    "        inputs = torch.tensor(x).view(1,1)\n",
    "        # print(inputs.shape)\n",
    "        \n",
    "        if(gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h, _ = model(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    " \n",
    "        if(gpu):\n",
    "            out = out.cpu() # move to cpu\n",
    "        \n",
    "        loss_min = float(\"inf\")\n",
    "        i = 0\n",
    "        for embd in embeddings:\n",
    "            loss = loss_f_1(torch.from_numpy(embd), torch.tensor(out)).mean()\n",
    "            loss = (1 - loss)/2\n",
    "            if loss < loss_min:\n",
    "                loss_min = loss\n",
    "                min_index = i\n",
    "            i += 1\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return idx2word[min_index] ,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that\n",
      "'\n",
      "s\n",
      "the\n",
      ".\n",
      "<repeated>\n",
      "<hashtag>\n",
      "not\n",
      "</hashtag>\n",
      "<hashtag>\n",
      "not\n",
      "</hashtag>\n",
      "<hashtag>\n",
      "lol\n",
      "</hashtag>\n",
      "<hashtag>\n",
      "not\n",
      "</hashtag>\n",
      "<hashtag>\n",
      "lol\n",
      "</hashtag>\n",
      "<hashtag>\n",
      "lol\n",
      "</hashtag>\n",
      "<hashtag>\n",
      "lol\n",
      "</hashtag>\n",
      "<hashtag>\n",
      "lol\n",
      "</hashtag>\n",
      "you are that that ' s the . <repeated> <hashtag> not </hashtag> <hashtag> not </hashtag> <hashtag> lol </hashtag> <hashtag> not </hashtag> <hashtag> lol </hashtag> <hashtag> lol </hashtag> <hashtag> lol </hashtag> <hashtag> lol </hashtag>\n"
     ]
    }
   ],
   "source": [
    "beginning = \"you are\"\n",
    "\n",
    "size = 30\n",
    "\n",
    "if(gpu):\n",
    "    model.cuda()\n",
    "else:\n",
    "    model.cpu()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "words = beginning.split()\n",
    "h = model.init_hidden(1)\n",
    "for word in words:\n",
    "    word_out, h = predict(model, word, h, loss_f)\n",
    "\n",
    "words.append(word_out)\n",
    "\n",
    "for i in range(size):\n",
    "    word_out, h = predict(model, words[-1], h)\n",
    "    print(word_out)\n",
    "    words.append(word_out)\n",
    "\n",
    "print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9667e-03, -7.0143e-01, -7.3567e-01,  ..., -2.2321e-01,\n",
       "          1.3087e-01, -3.3168e-01],\n",
       "        [ 4.6314e-01,  2.4860e+00, -1.2168e+00,  ..., -1.5734e+00,\n",
       "         -2.6471e-01, -1.7451e+00],\n",
       "        [-1.8289e-01,  6.3258e-01, -4.5826e-01,  ...,  2.2944e+00,\n",
       "         -2.3991e-01,  6.4642e-01],\n",
       "        ...,\n",
       "        [-1.0176e+00,  9.8853e-01,  8.9408e-01,  ...,  1.2193e+00,\n",
       "          2.8966e-01, -3.0660e-01],\n",
       "        [-8.2059e-01,  1.0942e+00, -4.7992e-01,  ..., -1.4636e+00,\n",
       "         -8.7323e-01, -4.8448e-01],\n",
       "        [ 2.9662e-01,  9.8677e-01, -1.0833e-01,  ..., -4.8979e-01,\n",
       "         -8.4017e-02, -3.8445e-01]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(100, 128)\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.8334e-04, -3.5071e-01, -3.6784e-01,  ..., -1.1161e-01,\n",
       "          6.5433e-02, -1.6584e-01],\n",
       "        [ 2.3157e-01,  1.2430e+00, -6.0840e-01,  ..., -7.8669e-01,\n",
       "         -1.3236e-01, -8.7255e-01],\n",
       "        [-9.1445e-02,  3.1629e-01, -2.2913e-01,  ...,  1.1472e+00,\n",
       "         -1.1995e-01,  3.2321e-01],\n",
       "        ...,\n",
       "        [-5.0881e-01,  4.9427e-01,  4.4704e-01,  ...,  6.0965e-01,\n",
       "          1.4483e-01, -1.5330e-01],\n",
       "        [-4.1029e-01,  5.4708e-01, -2.3996e-01,  ..., -7.3181e-01,\n",
       "         -4.3661e-01, -2.4224e-01],\n",
       "        [ 1.4831e-01,  4.9339e-01, -5.4164e-02,  ..., -2.4490e-01,\n",
       "         -4.2008e-02, -1.9223e-01]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1, 310])\n"
     ]
    }
   ],
   "source": [
    "word = 'you'\n",
    "x = word2idx[word]\n",
    "inputs = torch.tensor(x).view(1,1)\n",
    "print(inputs.shape)\n",
    "\n",
    "if(gpu):\n",
    "    inputs = inputs.cuda()\n",
    "    \n",
    "h = model.init_hidden(1)\n",
    "embd = model.embedding(inputs.long())\n",
    "if embd.shape[1] != 1:\n",
    "    embd_input = embd[:,:-1,:]\n",
    "    embd_target = embd[:,1:,:]\n",
    "else:\n",
    "    embd_input = embd\n",
    "    embd_target = embd\n",
    "\n",
    "# pack the batch\n",
    "# packed = pack_padded_sequence(embd, list(lengths.data),\n",
    "#                       batch_first=True)\n",
    "print(embd_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804871, 310)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   421,    68,  ...,     0,     0,     0],\n",
      "        [    1,     1,    69,  ...,     0,     0,     0],\n",
      "        [ 2442,   428, 26818,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  138,    10,     9,  ...,     0,     0,     0],\n",
      "        [    1,    80, 40702,  ...,     0,     0,     0],\n",
      "        [   70,  1036,   106,  ...,     0,     0,     0]], dtype=torch.int32)\n",
      "torch.Size([32, 47, 310]) torch.Size([32, 47, 310])\n",
      "torch.Size([32, 47])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-9817e6cfce9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;31m# opt.step()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clip' is not defined"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "h = model.init_hidden(model_conf['batch_train'])\n",
    "\n",
    "for i_batch, (X, lengths, index) in enumerate(loaders):\n",
    "    counter += 1\n",
    "\n",
    "    loss_f = nn.CosineSimilarity(dim=2, eps=1e-08)\n",
    "    \n",
    "    print(X)\n",
    "    \n",
    "    if(gpu):\n",
    "        X, lengths = X.to(device), lengths.to(device)\n",
    "\n",
    "    # opt.zero_grad()\n",
    "\n",
    "    linear_outputs, h, embd_target = model(X, h, lengths)\n",
    "    \n",
    "    print(linear_outputs.shape, embd_target.shape)\n",
    "\n",
    "    loss = loss_f(linear_outputs, embd_target)\n",
    "    print(loss.shape)\n",
    "    loss.sum().backward()\n",
    "\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    # opt.step()\n",
    "\n",
    "    if counter % print_every == 0:\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Step: {}...\".format(counter),\n",
    "              \"Loss: {:.4f}...\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 20, 20]) torch.Size([1, 2, 20, 20]) torch.Size([1, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.abs(torch.randn(1,2,20, 20))\n",
    "input2 = torch.abs(torch.randn(1,2,20, 20))\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(input1, input2)\n",
    "input1\n",
    "print(input1.shape, input2.shape, output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "    \n",
    "if(gpu):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:251: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'model_b_310_10e.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PreProcessing dataset None...: 100%|███████████████████████████████████████████████| 784/784 [00:00<00:00, 3417.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 17462, Total unks:42 (0.24%)\n",
      "Unique words: 3420, Unique unks:42 (1.23%)\n",
      "Labels statistics:\n",
      "{'0': '60.33%', '1': '20.92%', '2': '10.84%', '3': '7.91%'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_data = WordDataset(datasets['gold'][0],datasets['gold'][1],word2idx,pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_size = len(gold_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "ys = []\n",
    "lengths = []\n",
    "for X, y, length, index in gold_data:\n",
    "    Xs.append(torch.from_numpy(X))\n",
    "    ys.append(int(y))\n",
    "    lengths.append(int(length))\n",
    "Xs = torch.stack(Xs)\n",
    "ys = torch.tensor(ys)\n",
    "lengths = torch.tensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = model(Xs.to(torch.device('cuda')), lengths.to(torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_argmax = test_outputs.max(1)[1].to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443877696990967"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = torch.mean((test_argmax == ys).float()).item()\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_list = [tensor.item() for tensor in test_outputs.max(1)[1]]\n",
    "ys_list = [tensor.item() for tensor in ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443877551020407"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = f1_score(ys_list, argmax_list, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "0.84375\n",
      "<class 'torch.Tensor'>\n",
      "0.8125\n",
      "<class 'torch.Tensor'>\n",
      "0.875\n",
      "<class 'torch.Tensor'>\n",
      "0.90625\n",
      "<class 'torch.Tensor'>\n",
      "0.9375\n",
      "<class 'torch.Tensor'>\n",
      "0.78125\n",
      "<class 'torch.Tensor'>\n",
      "0.9375\n",
      "<class 'torch.Tensor'>\n",
      "0.84375\n",
      "<class 'torch.Tensor'>\n",
      "0.8125\n",
      "<class 'torch.Tensor'>\n",
      "0.875\n",
      "<class 'torch.Tensor'>\n",
      "0.84375\n",
      "<class 'torch.Tensor'>\n",
      "0.78125\n",
      "<class 'torch.Tensor'>\n",
      "0.90625\n",
      "<class 'torch.Tensor'>\n",
      "0.875\n",
      "<class 'torch.Tensor'>\n",
      "0.875\n",
      "<class 'torch.Tensor'>\n",
      "0.78125\n",
      "<class 'torch.Tensor'>\n",
      "0.9375\n",
      "<class 'torch.Tensor'>\n",
      "0.78125\n",
      "<class 'torch.Tensor'>\n",
      "0.8125\n",
      "<class 'torch.Tensor'>\n",
      "0.90625\n",
      "<class 'torch.Tensor'>\n",
      "0.84375\n",
      "<class 'torch.Tensor'>\n",
      "0.78125\n",
      "<class 'torch.Tensor'>\n",
      "0.9375\n",
      "<class 'torch.Tensor'>\n",
      "0.78125\n"
     ]
    }
   ],
   "source": [
    "loss_f = torch.nn.MultiLabelSoftMarginLoss()\n",
    "X_list = []\n",
    "y_list = []\n",
    "for i_batch, (X, y, lengths, index) in enumerate(loaders['gold'], 1):\n",
    "    y_raw = np.array(list(map(int,y)))\n",
    "    y_onehot = np.zeros((y_raw.shape[0], 4))\n",
    "    y_onehot[np.arange(y_raw.shape[0]), y_raw] = 1\n",
    "    y = torch.from_numpy(y_onehot).float()\n",
    "    if(gpu):\n",
    "        X, y, lengths = X.to(device), y.to(device), lengths.to(device)\n",
    "            \n",
    "    linear_outputs = model(X, lengths) \n",
    "    loss = loss_f(linear_outputs, y)\n",
    "    argmax = linear_outputs.max(1)[1]\n",
    "    print(np.mean(np.array(argmax.to(torch.device('cpu'))) == y_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  170,    77, 14161,  ...,     0,     0,     0],\n",
      "        [    1,   184,    54,  ...,     0,     0,     0],\n",
      "        [    6,    46,   331,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,     6,    45,  ...,     0,     0,     0],\n",
      "        [  170,   850,    23,  ...,     0,     0,     0],\n",
      "        [    6,   237,    25,  ...,     0,     0,     0]], dtype=torch.int32)\n",
      "('1', '0', '1', '0', '0', '3', '0', '1', '1', '0', '1', '3', '1', '1', '0', '1', '3', '1', '1', '2', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '1', '1')\n"
     ]
    }
   ],
   "source": [
    "for i_batch, (X, y, lengths, index) in enumerate(loaders['train'], 1):\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
